import pandas as pd
from typing import Optional, List, Dict

import logging
logger = logging.getLogger(__name__)


class BlockAwareFeatureEngineer:
    """Class for block-aware feature engineering."""

    def __init__(self, blocks: Dict[int, Dict[str, List[int]]]):
        self.blocks = blocks
        self._block_map = {
            idx: blk
            for blk, info in self.blocks.items()
            for idx in info["bucket_indices"]
        }
    
    def _assign_block_id(self, df: pd.DataFrame) -> pd.Series:
        """Internal helper: map each bucket_idx to its block_id so we can group by block."""
        return df["bucket_idx"].map(self._block_map)

    def add_moving_average_features(self,
                                    windows: List[int],
                                    shift_amount: int,
                                    data_frame: pd.DataFrame,
                                    cols: Optional[List[str]] = None,
                                    use_only_original_columns: bool = True,
                                    extra_grouping_cols: Optional[List[str]] = None
                                    ) -> pd.DataFrame:
        """
        For each col in `cols` (default: all numeric except 'bucket_idx'),
        create backward-looking moving averages of the past values,
        per block (so no cross‐block leakage).
                
        Args:
            windows: list of window sizes, e.g. [3, 24].
            shift_amount: how many steps to shift before averaging.
            data_frame: pd.DataFrame.
            cols: which columns to average; defaults to all numeric features.
            use_only_original_columns: whether to ignore columns generated by previous calls to 
                                       `add_moving_average_features` or `add_lag_features`).
                                       This prevents creating MAs of MAs or MAs of lags.
            extra_grouping_cols: any additional grouping columns (like 'room_uri_str'), additional to ['block_id'].
        """
        df = data_frame.copy()

        # Assign block ID to df
        df["block_id"] = self._assign_block_id(df)

        # Grouping
        grouping = ['block_id']
        if extra_grouping_cols:
            grouping.extend(extra_grouping_cols)
        logger.info(f"Adding moving average features, grouping by: {grouping}")

        # Sorting based on grouping + bucket_idx
        df.sort_values(grouping + ['bucket_idx'], inplace=True)

        # Pick which columns to do moving average
        if cols is None:
            # start from every numeric column except bucket_idx/block_id
            all_num = df.select_dtypes("number").columns.tolist()
            candidates = [c for c in all_num if c not in ("bucket_idx", "block_id")]
            if use_only_original_columns:
                # filter out any generated MA or lag columns
                cols = [
                    c for c in candidates
                    if "_ma_" not in c and "_lag_" not in c
                ]
            else:
                cols = candidates

        # Use vectorized operations to compute everything
        moving_average_dict = {}
        for w in windows:
            for col in cols:
                # Chain operations directly on the grouped series
                series = (
                    df.groupby(grouping)[col]
                    .shift(shift_amount)
                    .rolling(window=w, min_periods=1)
                    .mean()
                )
                moving_average_dict[f"{col}_ma_{w}_sh{shift_amount}"] = series
        
        # Concatenate all columns in one go
        ma_df = pd.DataFrame(moving_average_dict, index=df.index)
        df = pd.concat([df, ma_df], axis=1)

        # Drop helper
        df.drop(columns='block_id', inplace=True)

        return df

    def add_lag_features(self,
                        lags: List[int],
                        data_frame: pd.DataFrame,
                        cols: Optional[List[str]] = None,
                        use_only_original_columns: bool = True,
                        extra_grouping_cols: Optional[List[str]] = None,
                        ) -> pd.DataFrame:
        """
        For each col in `cols` (default: all numeric except 'bucket_idx'), 
        create lag‐k features per block (no leakage across train/val/test).

        Args:
            lags: list of integers, e.g. [1, 24]
            data_frame: pd.DataFrame.
            cols: which columns to lag; defaults to all numeric features.
            use_only_original_columns: whether to ignore columns generated by previous calls to 
                                       `add_moving_average_features` or `add_lag_features`).
                                       This prevents creating MAs of MAs or MAs of lags.
            extra_grouping_cols: any additional grouping columns (like 'room_uri_str'), additional to ['block_id'].
        """
        df = data_frame.copy()

        # Assign block ID to df
        df["block_id"] = self._assign_block_id(df)

        # Grouping
        grouping = ['block_id']
        if extra_grouping_cols:
            grouping.extend(extra_grouping_cols)
        logger.info(f"Adding lag features, grouping by: {grouping}")

        # Sorting based on grouping + bucket_idx
        df.sort_values(grouping + ['bucket_idx'], inplace=True)

        # Pick which columns to lag
        if cols is None:
            # start from every numeric column except bucket_idx/block_id
            all_num = df.select_dtypes("number").columns.tolist()
            candidates = [c for c in all_num if c not in ("bucket_idx", "block_id")]
            if use_only_original_columns:
                # filter out any generated MA or lag columns
                cols = [
                    c for c in candidates
                    if "_ma_" not in c and "_lag_" not in c
                ]
            else:
                cols = candidates

        # For each lag and each column
        lag_dict = {}
        gb = df.groupby(grouping)
        for k in lags:
            for col in cols:
                lag_series = gb[col].shift(k)
                lag_dict[f"{col}_lag_{k}"] = lag_series

        # Concatenate all columns in one go
        lag_df = pd.DataFrame(lag_dict, index=df.index)
        df = pd.concat([df, lag_df], axis=1)

        # Drop helper
        df.drop(columns='block_id', inplace=True)

        return df
