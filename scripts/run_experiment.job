#!/bin/bash

#SBATCH --job-name=stgcn
#SBATCH --partition=gpu_h100
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G
#SBATCH --time=03:00:00
#SBATCH --array=0-9
#SBATCH --output=output/experiments/slurm_output_%A_%a.out # %A=job ID, %a=array task ID
#SBATCH --error=output/experiments/slurm_error_%A_%a.err

# Define a base output directory for the entire job array
# SLURM_ARRAY_JOB_ID is the same for all jobs in the array
export BASE_OUTPUT_DIR=output/experiments/stgcn_${SLURM_ARRAY_JOB_ID}

# Define a specific output directory for this single task in the array
# SLURM_ARRAY_TASK_ID is unique for each job (0, 1, 2, ...)
export TASK_OUTPUT_DIR=${BASE_OUTPUT_DIR}/experiment_${SLURM_ARRAY_TASK_ID}
mkdir -p $TASK_OUTPUT_DIR

# Load modules
module purge
module load 2023
module load Python/3.11.3-GCCcore-12.3.0
module load CUDA/12.1.1
module load cuDNN/8.9.2.26-CUDA-12.1.1
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
module load Python-bundle-PyPI/2023.06-GCCcore-12.3.0
module load matplotlib/3.7.2-gfbf-2023a
module load scikit-learn/1.3.1-gfbf-2023a

# Set PyTorch optimization flags
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
export NCCL_DEBUG=INFO

# Move into your project directory (safety)
cd $HOME/eSTGNN

# Create directories on scratch space
mkdir -p $TMPDIR/data/processed


##### Dynamically copying the required file to scratch #####
echo "Determining required data file..."
REQUIRED_FILE=$(srun python -m src.utils.filename_util "$@")

# Checking if it returned a filename
if [ -z "$REQUIRED_FILE" ]; then
    echo "ERROR: Helper script could not determine a filename from the arguments."
    exit 1
fi

# Define the full source and destination paths
SOURCE_PATH="$HOME/eSTGNN/data/processed/$REQUIRED_FILE"
DEST_PATH="$TMPDIR/data/processed/$REQUIRED_FILE"

# Checking if the required file actually exists before trying to copy
if [ ! -f "$SOURCE_PATH" ]; then
    echo "ERROR: Required data file not found at: $SOURCE_PATH"
    exit 1
fi

# Copying the required file to scratch
echo "Copying required file '$REQUIRED_FILE' to scratch space..."
cp "$SOURCE_PATH" "$DEST_PATH"

# Final check
if [ ! -f "$DEST_PATH" ]; then
    echo "ERROR: Failed to copy '$REQUIRED_FILE' to scratch space."
    exit 1
fi
##### Dynamically copying the required file to scratch #####


# Set directories
export DATA_DIR=$TMPDIR/data

echo "Job Array Task ID: ${SLURM_ARRAY_TASK_ID}"
echo "Starting training with data from $DATA_DIR"
echo "Results for this task will be saved to $TASK_OUTPUT_DIR"

# Run script pointing to scratch, passing the unique experiment_id and output directory
srun python -m src.models.STGCN4B.homogeneous.experiment \
  --data_dir $DATA_DIR \
  --output_dir $TASK_OUTPUT_DIR \
  --experiment_id ${SLURM_ARRAY_TASK_ID} \
  --enable_cuda \
  "$@"

echo "Cleaning up scratch space..."
rm -rf $TMPDIR/data

echo "Job task ${SLURM_ARRAY_TASK_ID} completed successfully!"