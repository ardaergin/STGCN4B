#!/bin/bash

#SBATCH --job-name=lgbm-array
#SBATCH --partition=rome
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G
#SBATCH --time=05:00:00
#SBATCH --array=0-9
#SBATCH --output=output/experiments/lgbm/slurm_output_%A_%a.out # %A=job ID, %a=array task ID
#SBATCH --error=output/experiments/lgbm/slurm_error_%A_%a.err


# --- 1. DEFINE PERSISTENT STORAGE DIRECTORIES ---
PERSISTENT_PROJECT_DIR=$HOME/eSTGNN
PERSISTENT_DATA_DIR=$PERSISTENT_PROJECT_DIR/data
PERSISTENT_PROCESSED_DATA_DIR=$PERSISTENT_DATA_DIR/processed
PERSISTENT_LOG_DIR=$PERSISTENT_PROJECT_DIR/output/experiments/lgbm

# Base output directory on persistent storage for the entire job array
PERSISTENT_BASE_OUTPUT_DIR=$PERSISTENT_PROJECT_DIR/output/experiments/lgbm/lgbm_array_${SLURM_ARRAY_JOB_ID}
# A unique output directory on persistent storage for this specific task's final results
PERSISTENT_TASK_OUTPUT_DIR=$PERSISTENT_BASE_OUTPUT_DIR/experiment_${SLURM_ARRAY_TASK_ID}


# --- 2. DEFINE SCRATCH SPACE DIRECTORIES ---
SCRATCH_PROJECT_DIR=$TMPDIR/eSTGNN
SCRATCH_DATA_DIR=$SCRATCH_PROJECT_DIR/data
SCRATCH_PROCESSED_DATA_DIR=$SCRATCH_DATA_DIR/processed

# The training script will write its output here on the fast scratch disk for this task
SCRATCH_RUN_OUTPUT_DIR=$SCRATCH_PROJECT_DIR/output/experiment_${SLURM_ARRAY_TASK_ID}


# --- 3. ENSURE ALL NECESSARY DIRECTORIES EXIST ---
echo "Creating directories..."
# Create persistent directories for final results and logs
# The -p flag ensures parent directories (like the base output) are also created
mkdir -p $PERSISTENT_TASK_OUTPUT_DIR
mkdir -p $PERSISTENT_LOG_DIR

# Create scratch directories for the job to run in
mkdir -p $SCRATCH_PROCESSED_DATA_DIR
mkdir -p $SCRATCH_RUN_OUTPUT_DIR


# --- 4. LOAD MODULES ---
echo "Loading required modules..."
module purge
module load 2023
module load Python/3.11.3-GCCcore-12.3.0
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
module load Python-bundle-PyPI/2023.06-GCCcore-12.3.0
module load matplotlib/3.7.2-gfbf-2023a
module load scikit-learn/1.3.1-gfbf-2023a


# --- 5. PREPARE DATA ON SCRATCH ---
echo "Copying input data from persistent storage to scratch space..."
rsync -a --info=progress2 "$PERSISTENT_PROCESSED_DATA_DIR/" "$SCRATCH_PROCESSED_DATA_DIR"

# Check if data copy succeeded
if [ ! -d "$SCRATCH_PROCESSED_DATA_DIR" ] || [ -z "$(ls -A "$SCRATCH_PROCESSED_DATA_DIR")" ]; then
    echo "ERROR: Data directory not copied to scratch space correctly"
    exit 1
fi
echo "Data copy complete."

# Set environment variables for performance
echo "Setting OMP_NUM_THREADS and NUMEXPR_NUM_THREADS to $SLURM_CPUS_PER_TASK"
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
export NUMEXPR_NUM_THREADS=$SLURM_CPUS_PER_TASK


# --- 6. RUN THE PYTHON SCRIPT ---
echo "Starting Python script for Job Array Task ID: ${SLURM_ARRAY_TASK_ID}"
echo "Project running from: $PERSISTENT_PROJECT_DIR"
echo "Input data is read from: $SCRATCH_DATA_DIR"
echo "Output will be written to: $SCRATCH_RUN_OUTPUT_DIR"

cd $PERSISTENT_PROJECT_DIR

srun python -m src.models.LightGBM.experiment \
    --data_dir $SCRATCH_DATA_DIR \
    --output_dir $SCRATCH_RUN_OUTPUT_DIR \
    --processed_data_dir $SCRATCH_PROCESSED_DATA_DIR \
    --experiment_id ${SLURM_ARRAY_TASK_ID} \
    --model_family tabular \
    --model LightGBM \
    "$@"


# --- 7. COPY RESULTS BACK TO PERSISTENT STORAGE ---
echo "Copying results from scratch back to persistent storage..."
rsync -a "$SCRATCH_RUN_OUTPUT_DIR/" "$PERSISTENT_TASK_OUTPUT_DIR/"
echo "Results for task ${SLURM_ARRAY_TASK_ID} successfully copied to $PERSISTENT_TASK_OUTPUT_DIR"


# --- 8. CLEAN UP SCRATCH SPACE ---
echo "Cleaning up scratch space..."
rm -rf $TMPDIR/*

echo "Job task ${SLURM_ARRAY_TASK_ID} completed successfully!"