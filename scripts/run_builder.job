#!/bin/bash

#SBATCH --partition=rome
#SBATCH --job-name=officegraph_builder
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G
#SBATCH --time=00:10:00
#SBATCH --output=logs/builder/%A.out
#SBATCH --error=logs/builder/%A.err


# --- 1. DEFINE PERSISTENT STORAGE DIRECTORIES ---
PERSISTENT_PROJECT_DIR=$HOME/eSTGNN
PERSISTENT_DATA_DIR=$PERSISTENT_PROJECT_DIR/data
PERSISTENT_PROCESSED_DATA_DIR=$PERSISTENT_DATA_DIR/processed
PERSISTENT_PLOTS_DIR=$PERSISTENT_PROJECT_DIR/output/visualizations
PERSISTENT_LOG_DIR=$PERSISTENT_PROJECT_DIR/logs/builder


# --- 2. DEFINE SCRATCH SPACE DIRECTORIES ---
SCRATCH_PROJECT_DIR=$TMPDIR/eSTGNN
SCRATCH_DATA_DIR=$SCRATCH_PROJECT_DIR/data
SCRATCH_PROCESSED_DATA_DIR=$SCRATCH_PROJECT_DIR/data/processed
SCRATCH_PLOTS_DIR=$SCRATCH_PROJECT_DIR/output/visualizations


# --- 3. ENSURE ALL NECESSARY DIRECTORIES EXIST ---
# Create persistent directories for final results
mkdir -p $PERSISTENT_PROCESSED_DATA_DIR
mkdir -p $PERSISTENT_PLOTS_DIR
mkdir -p $PERSISTENT_LOG_DIR

# Create scratch directories for the job to run in
mkdir -p $SCRATCH_DATA_DIR
mkdir -p $SCRATCH_PROCESSED_DATA_DIR
mkdir -p $SCRATCH_PLOTS_DIR


# --- 4. LOAD MODULES ---
module purge
module load 2023
module load Python/3.11.3-GCCcore-12.3.0
module load CUDA/12.1.1
module load cuDNN/8.9.2.26-CUDA-12.1.1
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
module load Python-bundle-PyPI/2023.06-GCCcore-12.3.0
module load matplotlib/3.7.2-gfbf-2023a
module load scikit-learn/1.3.1-gfbf-2023a


# --- 5. PREPARE DATA ON SCRATCH ---
echo "Copying input data from persistent storage to scratch space..."
cp -r $PERSISTENT_DATA_DIR/interim $SCRATCH_DATA_DIR/
cp -r $PERSISTENT_DATA_DIR/consumption $SCRATCH_DATA_DIR/
cp -r $PERSISTENT_DATA_DIR/weather $SCRATCH_DATA_DIR/

# Check if data copy succeeded
if [ ! -d "$SCRATCH_DATA_DIR/interim" ]; then
    echo "ERROR: Data directory not copied to scratch space correctly"
    exit 1
fi

# Set the number of threads for numexpr to match the CPUs requested from SLURM.
echo "Setting NUMEXPR_NUM_THREADS to $SLURM_CPUS_PER_TASK"
export NUMEXPR_NUM_THREADS=$SLURM_CPUS_PER_TASK


# --- 6. RUN THE PYTHON SCRIPT ---
echo "Starting Python script..."
echo "Project directory: $PERSISTENT_PROJECT_DIR"
echo "Input data is from: $SCRATCH_DATA_DIR"
echo "Processed data will be written to: $SCRATCH_PROCESSED_DATA_DIR"
echo "Plots will be written to: $SCRATCH_PLOTS_DIR"

cd $PERSISTENT_PROJECT_DIR

srun python -m src.graph.builder.main \
    --data_dir $SCRATCH_DATA_DIR \
    --processed_data_dir $SCRATCH_PROCESSED_DATA_DIR \
    --weather_csv_path $SCRATCH_DATA_DIR/weather/hourly_weather_2022_2023.csv \
    --consumption_dir $SCRATCH_DATA_DIR/consumption \
    --builder_plots_dir $SCRATCH_PLOTS_DIR \
    --make_and_save_plots \
    "$@"


# --- 7. COPY RESULTS BACK TO PERSISTENT STORAGE ---
echo "Copying processed data back to $PERSISTENT_PROCESSED_DATA_DIR..."
cp -r $SCRATCH_PROCESSED_DATA_DIR/* $PERSISTENT_PROCESSED_DATA_DIR/

echo "Copying plots back to $PERSISTENT_PLOTS_DIR..."
cp -r $SCRATCH_PLOTS_DIR/* $PERSISTENT_PLOTS_DIR/

# --- 8. CLEAN UP SCRATCH SPACE ---
echo "Cleaning up scratch space..."
rm -rf $TMPDIR/*

echo "Job completed successfully!"