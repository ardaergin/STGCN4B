#!/bin/bash

#SBATCH --partition=gpu_h100
#SBATCH --gpus=2
#SBATCH --job-name=stgcn
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --mem=64G
#SBATCH --time=01:00:00
#SBATCH --output=slurm_output_%A.out
#SBATCH --error=slurm_error_%A.err
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=your.email@domain.com

# Load modules
module purge
module load 2023
module load Python/3.11.3-GCCcore-12.3.0
module load CUDA/12.1.1
module load cuDNN/8.9.2.26-CUDA-12.1.1
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
module load Python-bundle-PyPI/2023.06-GCCcore-12.3.0
module load matplotlib/3.7.2-gfbf-2023a
module load scikit-learn/1.3.1-gfbf-2023a
pip install --user rdflib
pip install --user holidays

# Set PyTorch optimization flags
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
export NCCL_DEBUG=INFO

# Move into your project directory (safety)
cd $HOME/eSTGNN

# Create directories on scratch space
mkdir -p $TMPDIR/data/OfficeGraph/processed_data

# Copy data to scratch (fast local disk)
echo "Copying data to scratch space..."
cp $HOME/eSTGNN/data/OfficeGraph/processed_data/torch_input.pt $TMPDIR/data/OfficeGraph/processed_data/

# Check if data copy succeeded
if [ ! -f "$TMPDIR/data/OfficeGraph/processed_data/torch_input.pt" ]; then
  echo "ERROR: Failed to copy data file"
  exit 1
fi

# Set directories
export DATA_DIR=$TMPDIR/data/OfficeGraph
export OUTPUT_DIR=output/stgcn_${SLURM_JOB_ID}

echo "Starting training with data from $DATA_DIR"
echo "Results will be saved to $OUTPUT_DIR"

# Run script pointing to scratch
srun python -m src.models.stgcn.main \
  --data_dir $DATA_DIR \
  --output_dir $OUTPUT_DIR \
  --enable_cuda

# Check execution success
if [ $? -ne 0 ]; then
  echo "ERROR: Training script failed"
  exit 1
fi

# Copy results from scratch to home directory
echo "Copying results back to home directory..."
mkdir -p $HOME/eSTGNN/output
cp -r $OUTPUT_DIR $HOME/eSTGNN/output/

echo "Cleaning up scratch space..."
rm -rf $TMPDIR/data

echo "Job completed successfully!"
